---
seed: ~
run_id: mult-0.1-attn-g0.95-e0.05
group_id: big-obs
model_load_file: ~
features_extractor_load_file: ~
features_extractor_load_file_type: "params"  # model / params / sb3
features_extractor_freeze: false
notes: ""
out_dir_template: "data/{group_id}/{run_id}"
observations_dir: ~
log_tensorboard: true
progress_bar: false  # too annoying and noisy
# total_timesteps: !!float 100000
rollouts_total: 0
rollouts_per_iteration: 20
rollouts_per_log: 2
save_every: 7200  # seconds
max_saves: 3
iteration: 0  # start iteration (to skip first n_envs/2 maps)

# XXX: 21 envs require 256+ filehandles (and 256 is the limit by default)
#      To increase (current shell session only):
#           ulimit -n 1024
n_envs: 8
framestack: 1

# overwrites learner_kwargs.n_steps to n_global_steps_max // n_envs
# (eg. 2048/48 = 42.666... => n_steps=42)
n_global_steps_max: 1024

mapmask: "ai/generated/B*.vmap"
randomize_maps: false

logparams: {}
  # "config/weight_decay": "learner_kwargs.policy_kwargs.optimizer_kwargs.weight_decay"
  # "config/features_extractor": "learner_kwargs.policy_kwargs.features_extractor_class_name"
  # "config/optimizer": "learner_kwargs.policy_kwargs.optimizer_class_name"
  # "config/rew_clip": "env_kwargs.reward_clip_mod"

activation: "LeakyReLU"
net_arch: []
optimizer:
  class_name: "AdamW"
  kwargs: {eps: !!float 1e-5, weight_decay: 0}
features_extractor:
  class_name: "VcmiFeaturesExtractor"
  kwargs:
    layers:
        # => (B, 1, 11, 840)
        - {t: "Conv2d", out_channels: 32, kernel_size: [1, 4], stride: [1, 4], padding: 0}
        - {t: "BatchNorm2d", num_features: 32}
        - {t: "LeakyReLU"}
        # => (B, 32, 11, 210)
        - {t: "Conv2d", in_channels: 32, out_channels: 32, kernel_size: [1, 7], stride: [1, 7], padding: 0}
        - {t: "BatchNorm2d", num_features: 32}
        - {t: "LeakyReLU"}
        # => (B, 32, 11, 30)
        - {t: "Conv2d", in_channels: 32, out_channels: 32, kernel_size: [1, 2], stride: [1, 2], padding: 0}
        - {t: "BatchNorm2d", num_features: 32}
        - {t: "LeakyReLU"}
        # => (B, 32, 11, 15)
        - {t: "Flatten", start_dim: 2}
        # => (B, 32, 165)
        - {t: "Transpose", dim0: 1, dim1: 2}
        # => (B, 165, 32)  - 165 hexes, each with 32 layers of convoluted data
        - {t: "VcmiAttention", embed_dim: 32, num_heads: 8, batch_first: true}
        # => (B, 165, 32)
        - {t: "Flatten"}
        # => (B, 5280)
        - {t: "Linear", in_features: 5280, out_features: 1024}
        - {t: "LeakyReLU"}

learner_kwargs:
  # n_steps: 512  # calculated dynamically (see n_global_steps_max)
  batch_size: 64
  n_epochs: 10
  gamma: 0.95
  gae_lambda: 0.8
  clip_range: 0.4
  normalize_advantage: true
  ent_coef: 0.05
  vf_coef: 0.6
  max_grad_norm: 2.5

# Examples:
#   * "const_0.001"
#   * "lin_decay_0.03_0.0001_0.75"
#   * "exp_decay_0.03_0.0001_0.5_5"
learner_lr_schedule: "const_0.0005"

env_cls_name: VcmiEnv
env_kwargs:
  max_steps: 500
  reward_clip_mod: ~
  reward_dmg_factor: 0
  vcmi_loglevel_global: "error"
  vcmi_loglevel_ai: "error"
  vcmienv_loglevel: "WARN"
  consecutive_error_reward_factor: -1
  sparse_info: true
  step_reward_mult: 0.1
  term_reward_mult: 1

  # Set dynamically
  # mapname: "ai/generated/A01.vmap"
  # attacker: "MMAI_USER"  # MMAI_USER / MMAI_MODEL / StupidAI / BattleAI
  # defender: "StupidAI"   # MMAI_USER / MMAI_MODEL / StupidAI / BattleAI
  # attacker_model: ~  # MPPO zip model (if attacker=MMAI_MODEL)
  # defender_model: ~  # MPPO zip model (if defender=MMAI_MODEL)

env_wrappers: []

