---
seed: ~
run_id: mqrdqn-MM01-l3-bn-fdim1024
group_id: qrdqn
model_load_file: ~
# features_extractor_load_file: "autoencoder-pretrained-encoder-params.pth"
features_extractor_load_file: ~
features_extractor_load_file_type: "params"  # model / params / sb3
features_extractor_freeze: false
notes: ""
out_dir_template: "data/{group_id}/{run_id}"
observations_dir: ~
log_tensorboard: true
progress_bar: false  # too annoying and noisy
# total_timesteps: !!float 100000
rollouts_total: 0
rollouts_per_iteration: 100
rollouts_per_log: 2
save_every: 7200  # seconds
max_saves: 3
iteration: 0  # start iteration (to skip first n_envs/2 maps)

n_envs: 1
framestack: 1

logparams: {}
# n_global_steps_max: 1024

mapmask: "ai/M1.vmap"
randomize_maps: false

activation: "LeakyReLU"
net_arch: []
optimizer:
  class_name: "AdamW"
  kwargs: {eps: !!float 1e-5, weight_decay: 0}
features_extractor:
  class_name: "VcmiFeaturesExtractor"
  kwargs:
    layers:
        # => (11, 225)
        - {t: "Conv2d", out_channels: 32, kernel_size: [1, 16], stride: [1, 16], padding: 0}
        - {t: "BatchNorm2d", num_features: 32}
        - {t: "LeakyReLU"}
        # - {t: "Dropout2d", p: 0.25, inplace: true}
        # => (11, 15)
        - {t: "Conv2d", in_channels: 32, out_channels: 64, kernel_size: 3, stride: 2, padding: 0}
        - {t: "BatchNorm2d", num_features: 64}
        - {t: "LeakyReLU"}
        # - {t: "Dropout2d", p: 0.25, inplace: true}
        # => (5, 7)
        - {t: "Conv2d", in_channels: 64, out_channels: 64, kernel_size: 3, stride: 2, padding: 0}
        - {t: "BatchNorm2d", num_features: 64}
        - {t: "LeakyReLU"}
        # - {t: "Dropout2d", p: 0.25, inplace: true}
        # => (2, 3)
        - {t: "Flatten"}
        # => 384
        - {t: "Linear", in_features: 384, out_features: 1024}
        - {t: "LeakyReLU"}
        # => 1024

learner_kwargs:
  buffer_size: 50_000
  learning_starts: 10_000
  batch_size: 32
  tau: 1.0
  gamma: 0.8
  # will change map every rollouts_per_iteration * train_freq steps
  # train_freq=100, rollouts_per_iteration=100 => change map every 10K steps
  # buffer_size=50K => buffer will contain experience for last 5 maps
  # XXX: rollout every 100 steps means ~4 episodes/rollout
  #      => adjust stats_window_size=10 (if rollouts_per_log=2)
  train_freq: 100
  stats_window_size: 10
  gradient_steps: 1
  target_update_interval: 4000
  exploration_fraction: 1
  exploration_initial_eps: 0.5
  exploration_final_eps: 0.01
# learner_lr_schedule: "lin_decay_0.01_0.003_0.75"
# learner_lr_schedule: "lin_decay_0.01_0.003_0.0"
learner_lr_schedule: "const_0.0005"

env_kwargs:
  max_steps: 500
  reward_clip_mod: ~
  reward_dmg_factor: 5
  vcmi_loglevel_global: "error"
  vcmi_loglevel_ai: "error"
  vcmienv_loglevel: "WARN"
  consecutive_error_reward_factor: -1
  sparse_info: true
  allow_invalid_actions: True

  # Set dynamically
  # mapname: "ai/generated/A01.vmap"
  # attacker: "MMAI_USER"  # MMAI_USER / MMAI_MODEL / StupidAI / BattleAI
  # defender: "StupidAI"   # MMAI_USER / MMAI_MODEL / StupidAI / BattleAI
  # attacker_model: ~  # MPPO zip model (if attacker=MMAI_MODEL)
  # defender_model: ~  # MPPO zip model (if defender=MMAI_MODEL)

env_wrappers: []
