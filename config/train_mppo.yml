---
seed: ~
run_id: ~
group_id: ~
model_load_file: "data/MPPO-32q24d2n/32q24d2n_1704941195/model.zip"
out_dir_template: "data/MPPO-{group_id}/{run_id}"
log_tensorboard: true
progress_bar: false  # too annoying and noisy
# total_timesteps: !!float 100000
rollouts_total: 0
rollouts_per_iteration: 200
rollouts_per_log: 2
save_every: 600  # seconds
max_saves: 3

# XXX: 21 envs require 256+ filehandles (and 256 is the limit by default)
#      To increase (current shell session only):
#           ulimit -n 1024
n_envs: 8

# overwrites learner_kwargs.n_steps to n_global_steps_max // n_envs
# (eg. 2048/48 = 42.666... => n_steps=42)
n_global_steps_max: 1024

mapmask: "ai/generated/A0[0-4].vmap"
randomize_maps: False

logparams: {}
  # "config/weight_decay": "learner_kwargs.policy_kwargs.optimizer_kwargs.weight_decay"
  # "config/features_extractor": "learner_kwargs.policy_kwargs.features_extractor_class_name"
  # "config/optimizer": "learner_kwargs.policy_kwargs.optimizer_class_name"
  # "config/rew_clip": "env_kwargs.reward_clip_mod"

activation: "ReLU"
net_arch: [256, 256]
optimizer:
  class_name: "AdamW"
  kwargs: {eps: !!float 1e-5, weight_decay: 0}
features_extractor:
  class_name: "VcmiFeaturesExtractor"
  kwargs:
    output_dim: 1024
    activation: "ReLU"
    layers:
        - {t: "Conv2d", out_channels: 32, kernel_size: [1, 15], stride: [1, 15], padding: 0}
        # - {t: "Conv2d", in_channels: 32, out_channels: 64, kernel_size: 3, stride: 1, padding: 1}
        # - {t: "Conv2d", in_channels: 64, out_channels: 64, kernel_size: 5, stride: 1, padding: 2}

learner_kwargs:
  # n_steps: 512  # calculated dynamically (see n_global_steps_max)
  batch_size: 64
  n_epochs: 10
  gamma: 0.8425
  gae_lambda: 0.8
  clip_range: 0.4
  normalize_advantage: true
  ent_coef: 0.007
  vf_coef: 0.6
  max_grad_norm: 2.5

# Examples:
#   * "const_0.001"
#   * "lin_decay_0.03_0.0001_0.75"
#   * "exp_decay_0.03_0.0001_0.5_5"
learner_lr_schedule: "const_0.0006"

env_kwargs:
  max_steps: 500
  reward_clip_mod: ~
  vcmi_loglevel_global: "error"
  vcmi_loglevel_ai: "error"
  vcmienv_loglevel: "WARN"
  consecutive_error_reward_factor: -1
  sparse_info: true

  # Set dynamically
  # mapname: "ai/generated/A01.vmap"
  # attacker: "MMAI_USER"  # MMAI_USER / MMAI_MODEL / StupidAI / BattleAI
  # defender: "StupidAI"   # MMAI_USER / MMAI_MODEL / StupidAI / BattleAI
  # attacker_model: ~  # MPPO zip model (if attacker=MMAI_MODEL)
  # defender_model: ~  # MPPO zip model (if defender=MMAI_MODEL)

env_wrappers: []

