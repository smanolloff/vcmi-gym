Good explanation here:
https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html#default-network-architecture

How .predict works:

.predict(obs)
  1. extract features
    (eg. for NatureCNN, the extracted features are features_dim, ie. 512)

    This results in 512 ouputs.
    In https://poloclub.github.io/cnn-explainer/ the 512 outputs (features)
    correspond to the 512 labels (10 in their case).

  [SAC/TD3 only]
  2. feed those results (called latent codes) to to a latent network
      `latent_pi` - an MLP network (?with (64,64) size?):

        features = super().extract_features(obs, self.pi_features_extractor)
        latent_pi = self.mlp_extractor.forward_actor(features)


    This results in `last_layer_dim_pi` outputs, eg. 64

  [ALL]
  3. Feed those results in an action-distribution network:
    a linear net with shape (last_layer_dim_pi, n_actions), eg. (64, 1323)
    (see proba_distribution_net() for CategoricalDistribution)

      in _get_action_dist_from_latent(latent_pi):

        mean_actions = self.action_net(latent_pi)

    This results in `action_space` outputs, eg. 1323 of logits
    (logits=unnormalized outputs)

  4. Feed those results in a probability dist function (Eg. softmax):

      in _get_action_dist_from_latent(latent_pi):

        return self.action_dist.proba_distribution(action_logits=mean_actions)
          -> Categorical(logits=action_logits)

          this performs softmax and outputs a *distribution*
          When sampled, the output is an integer of between 0 and len(action_logits)
          See https://pytorch.org/docs/stable/distributions.html#categorical
