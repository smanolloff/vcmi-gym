---
group_id: crl
run_id: crl-mult-sanity2-lr0.001
resume: False
overwrite: []
# overwrite: ["learning_rate", "env.term_reward_mult"]

notes: ~

agent_load_file: "data/crl/crl-mult-sanity2-lr0.0001/agent-1709634350.pt"
rollouts_total: 10000
rollouts_per_mapchange: 20
rollouts_per_log: 1
opponent_load_file: ~
success_rate_target: ~
mapmask: "ai/generated/B*.vmap"
randomize_maps: false
save_every: 3600  # seconds
max_saves: 3
out_dir_template: "data/{group_id}/{run_id}"

# XXX: 21 envs require 256+ filehandles (and 256 is the limit by default)
#      To increase (current shell session only):
#           ulimit -n 1024
num_envs: 8

#
# PPO Hyperparams
#
learning_rate: 0.001
num_steps: 128       # rollout_buffer = num_steps*num_envs
num_minibatches: 16  # minibatch_size = rollout_buffer/num_minibatches
update_epochs: 10    # full passes of rollout_buffer
gamma: 0.8425
gae_lambda: 0.8
norm_adv: true
clip_coef: 0.4
clip_vloss: True
ent_coef: 0.007
vf_coef: 0.6
max_grad_norm: 2.5
target_kl: ~

env:
  max_steps: 500
  reward_dmg_factor: 5
  vcmi_loglevel_global: "error"
  vcmi_loglevel_ai: "error"
  vcmienv_loglevel: "WARN"
  consecutive_error_reward_factor: -1
  sparse_info: true
  step_reward_mult: 1
  term_reward_mult: 0
  reward_clip_mod: ~

  # 0=hex.id, 1=hex.state, 2=qty, 12=qpos, 13=side, 15=creature type
  #   Visualize with:
  #   o = obs.reshape(11, 15, 6)[0][0] * [164, 4, 5001, 15, 2, 151])
  #   o.astype(int)
  # hexattr_filter: [0, 1, 2, 12, 13, 15]

  # Set dynamically
  # mapname: "ai/generated/A01.vmap"
  # attacker: "MMAI_USER"  # MMAI_USER / MMAI_MODEL / StupidAI / BattleAI
  # defender: "StupidAI"   # MMAI_USER / MMAI_MODEL / StupidAI / BattleAI
  # attacker_model: ~  # MPPO zip model (if attacker=MMAI_MODEL)
  # defender_model: ~  # MPPO zip model (if defender=MMAI_MODEL)

env_wrappers: []

