{
    "actual_training_ratio": "Stats(1.0; len=1; reduce=mean; win=1)",
    "env_runners": {
        "episode_duration_sec_mean": "Stats(0.0; len=1000; reduce=mean; win=1000)",
        "episode_len_max": "Stats(100; len=1; reduce=max)",
        "episode_len_mean": "Stats(4.0; len=1000; reduce=mean; win=1000)",
        "episode_len_min": "Stats(1; len=1; reduce=min)",
        "episode_return_max": "Stats(895.0304313105473; len=1; reduce=max)",
        "episode_return_mean": "Stats(-492.20248039661516; len=1000; reduce=mean; win=1000)",
        "episode_return_min": "Stats(-1104.1119761984771; len=1; reduce=min)",
        "num_agent_steps_sampled": {
            "default_agent": "Stats(1024; len=1; reduce=sum)"
        },
        "num_agent_steps_sampled_lifetime": {
            "default_agent": "Stats(1047553; len=1; reduce=sum)"
        },
        "num_env_steps_sampled": "Stats(1024; len=1; reduce=sum)",
        "num_env_steps_sampled_lifetime": "Stats(1047553; len=1; reduce=sum)",
        "num_episodes": "Stats(121; len=1; reduce=sum)",
        "num_module_steps_sampled": {
            "default_policy": "Stats(1024; len=1; reduce=sum)"
        },
        "num_module_steps_sampled_lifetime": {
            "default_policy": "Stats(1047553; len=1; reduce=sum)"
        },
        "user/is_success": "Stats(0.0; len=1000; reduce=mean; win=1000)",
        "user/net_value": "Stats(-15.0; len=1000; reduce=mean; win=1000)"
    },
    "learners": {
        "__all_modules__": {
            "num_env_steps_trained": "Stats(16; len=1; reduce=sum)",
            "num_module_steps_trained": "Stats(16; len=1; reduce=sum)"
        },
        "default_policy": {
            "ACTOR_L_neg_entropy_term": "Stats(-0.002313567092642188; len=1; reduce=mean; win=1)",
            "ACTOR_L_neglogp_reinforce_term": "Stats(-2.400745153427124; len=1; reduce=mean; win=1)",
            "ACTOR_L_total": "Stats(-0.3509185016155243; len=1; reduce=mean; win=1)",
            "ACTOR_action_entropy": "Stats(7.711889743804932; len=1; reduce=mean; win=1)",
            "ACTOR_gradients_global_norm": "Stats(0.0; len=1; reduce=mean; win=1)",
            "ACTOR_gradients_maxabs_after_clipping": "Stats(-inf; len=1; reduce=mean; win=1)",
            "ACTOR_value_targets_pct5_ema": "Stats(-5.582384119406925e-07; len=1; reduce=mean; win=1)",
            "ACTOR_value_targets_pct95_ema": "Stats(-1.1920928955078125e-07; len=1; reduce=mean; win=1)",
            "CRITIC_L_neg_logp_of_value_targets": "Stats(5.541260242462158; len=1; reduce=mean; win=1)",
            "CRITIC_L_slow_critic_regularization": "Stats(5.541260242462158; len=1; reduce=mean; win=1)",
            "CRITIC_L_total": "Stats(1.6052258014678955; len=1; reduce=mean; win=1)",
            "CRITIC_gradients_global_norm": "Stats(0.0; len=1; reduce=mean; win=1)",
            "CRITIC_gradients_maxabs_after_clipping": "Stats(-inf; len=1; reduce=mean; win=1)",
            "VALUE_TARGETS_H_BxT": "Stats(-2.5589548613424995e-07; len=1; reduce=mean; win=1)",
            "WORLD_MODEL_L_continue": "Stats(0.6982297897338867; len=1; reduce=mean; win=1)",
            "WORLD_MODEL_L_decoder": "Stats(702.4835205078125; len=1; reduce=mean; win=1)",
            "WORLD_MODEL_L_dynamics": "Stats(4.204427719116211; len=1; reduce=mean; win=1)",
            "WORLD_MODEL_L_prediction": "Stats(708.7230224609375; len=1; reduce=mean; win=1)",
            "WORLD_MODEL_L_representation": "Stats(4.204427719116211; len=1; reduce=mean; win=1)",
            "WORLD_MODEL_L_reward": "Stats(5.541260719299316; len=1; reduce=mean; win=1)",
            "WORLD_MODEL_L_total": "Stats(711.2457275390625; len=1; reduce=mean; win=1)",
            "WORLD_MODEL_gradients_global_norm": "Stats(215.75668334960938; len=1; reduce=mean; win=1)",
            "WORLD_MODEL_gradients_maxabs_after_clipping": "Stats(5.382375717163086; len=1; reduce=mean; win=1)",
            "WORLD_MODEL_learned_initial_h": "Stats(-2.3629363568034023e-06; len=1; reduce=mean; win=1)",
            "actor_learning_rate": "Stats(2.9999999242136255e-05; len=1; reduce=mean; win=1)",
            "critic_learning_rate": "Stats(2.9999999242136255e-05; len=1; reduce=mean; win=1)",
            "module_train_batch_size_mean": "Stats(16; len=1; reduce=mean; ema=0.01)",
            "num_module_steps_trained": "Stats(16; len=1; reduce=sum)",
            "total_loss": "Stats(712.5000610351562; len=1; reduce=mean; win=1)",
            "world_model_learning_rate": "Stats(9.999999747378752e-05; len=1; reduce=mean; win=1)"
        }
    },
    "num_agent_steps_sampled_lifetime": {
        "default_agent": "Stats(1024; len=1; reduce=sum)"
    },
    "num_env_steps_sampled_lifetime": "Stats(1024; len=1; reduce=sum)",
    "num_env_steps_trained_lifetime": "Stats(1024; len=1; reduce=sum)",
    "num_episodes_lifetime": "Stats(121; len=1; reduce=sum)",
    "num_grad_updates_lifetime": "Stats(1; len=1; reduce=sum)",
    "replay_buffer": {
        "added_steps": "Stats(1024.0; len=1; reduce=mean; win=1)",
        "capacity": "Stats(100000.0; len=1; reduce=mean; win=1)",
        "replayed_steps": "Stats(0.0; len=1; reduce=mean; win=1)",
        "size_num_episodes": "Stats(122.0; len=1; reduce=mean; win=1)",
        "size_timesteps": "Stats(1024.0; len=1; reduce=mean; win=1)"
    },
    "timers": {
        "garbage_collection": "Stats(0.23857320845127106; len=1; reduce=mean; ema=0.01)",
        "learn": "Stats(12.096429789438844; len=1; reduce=mean; ema=0.01)",
        "sample": "Stats(14.625837333500385; len=1; reduce=mean; ema=0.01)",
        "synch_weights": "Stats(4.958361387252808e-06; len=1; reduce=mean; ema=0.01)"
    }
}
